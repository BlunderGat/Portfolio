# -*- coding: utf-8 -*-
"""LAB3_3374_LIM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UxkRqFmYtSDipk76OPIcxu6ZONHefqhh
"""

# Лабораторная работа 3
# 3374
# Лобачев Иван Максимович
# Исследование алгоритмов классификации

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                           f1_score, classification_report, confusion_matrix,
                           roc_curve, auc, RocCurveDisplay)
from sklearn.multiclass import OneVsRestClassifier
from itertools import cycle
import warnings
warnings.filterwarnings('ignore')

plt.rcParams['figure.figsize'] = (12, 8)
sns.set_style("whitegrid")

# Загрузка и подготовка данных
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv"
df = pd.read_csv(url, sep=';')
print(f"Размер датасета: {df.shape}")

# Добавление новых атрибутов
df['acidity_ratio'] = df['fixed acidity'] / df['volatile acidity']
df['sulfur_ratio'] = df['free sulfur dioxide'] / df['total sulfur dioxide']

# Обработка бесконечных значений
df = df.replace([np.inf, -np.inf], np.nan)
df = df.fillna(df.median())

print("Добавлены новые атрибуты:")
print(f"Новый размер датасета: {df.shape}")
display(df.head())

# Анализ целевой переменной
print("АНАЛИЗ ЦЕЛЕВОЙ ПЕРЕМЕННОЙ (QUALITY):")

quality_distribution = df['quality'].value_counts().sort_index()
print("Распределение по классам качества:")
for quality, count in quality_distribution.items():
    percentage = (count / len(df)) * 100
    print(f"Качество {quality}: {count} образцов ({percentage:.1f}%)")

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

quality_distribution.plot(kind='bar', ax=ax1, color='skyblue', alpha=0.7)
ax1.set_xlabel('Качество вина')
ax1.set_ylabel('Количество образцов')
ax1.set_title('Распределение целевой переменной')
ax1.grid(True, alpha=0.3)

colors = plt.cm.Set3(np.linspace(0, 1, len(quality_distribution)))
ax2.pie(quality_distribution.values, labels=quality_distribution.index,
        autopct='%1.1f%%', colors=colors, startangle=90)
ax2.set_title('Процентное распределение качества')

plt.tight_layout()
plt.show()

# Анализ сбалансированности
print("АНАЛИЗ СБАЛАНСИРОВАННОСТИ КЛАССОВ:")
total_samples = len(df)
balance_ratio = quality_distribution.max() / quality_distribution.min()
print(f"Соотношение макс/мин класса: {balance_ratio:.2f}")

if balance_ratio > 5:
    print("Датсет НЕСБАЛАНСИРОВАН - требуется специальная обработка")
elif balance_ratio > 2:
    print("Датсет УМЕРЕННО СБАЛАНСИРОВАН")
else:
    print("Датсет ХОРОШО СБАЛАНСИРОВАН")

# Преобразование в бинарную классификацию
print("\nПРЕОБРАЗОВАНИЕ В БИНАРНУЮ КЛАССИФИКАЦИЮ:")
df['quality_binary'] = df['quality'].apply(lambda x: 1 if x >= 6 else 0)
binary_dist = df['quality_binary'].value_counts()
print("Бинарная классификация:")
print(f"Хорошее вино (>=6): {binary_dist[1]} образцов ({(binary_dist[1]/len(df))*100:.1f}%)")
print(f"Плохое вино (<6): {binary_dist[0]} образцов ({(binary_dist[0]/len(df))*100:.1f}%)")

plt.figure(figsize=(8, 6))
binary_dist.plot(kind='bar', color=['lightcoral', 'lightgreen'])
plt.title('Бинарная классификация качества вина')
plt.xlabel('Качество (0=Плохое, 1=Хорошее)')
plt.ylabel('Количество образцов')
plt.xticks(rotation=0)
plt.grid(True, alpha=0.3)
plt.show()

# Подготовка данных для обучения
features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',
           'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',
           'pH', 'sulphates', 'alcohol', 'acidity_ratio', 'sulfur_ratio']

X = df[features]
y_binary = df['quality_binary']
y_multiclass = df['quality']

X_train, X_test, y_binary_train, y_binary_test = train_test_split(
    X, y_binary, test_size=0.3, random_state=42, stratify=y_binary)

X_train_multi, X_test_multi, y_multi_train, y_multi_test = train_test_split(
    X, y_multiclass, test_size=0.3, random_state=42, stratify=y_multiclass)

print(f"Размер обучающей выборки: {X_train.shape}")
print(f"Размер тестовой выборки: {X_test.shape}")

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_multi_scaled = scaler.fit_transform(X_train_multi)
X_test_multi_scaled = scaler.transform(X_test_multi)

# Функция для оценки моделей
def evaluate_model(model, X_train, X_test, y_train, y_test, model_name, multiclass=False):
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    y_pred_proba = model.predict_proba(X_test) if hasattr(model, 'predict_proba') else None

    accuracy = accuracy_score(y_test, y_pred)

    if multiclass:
        precision = precision_score(y_test, y_pred, average='weighted')
        recall = recall_score(y_test, y_pred, average='weighted')
        f1 = f1_score(y_test, y_pred, average='weighted')
    else:
        precision = precision_score(y_test, y_pred)
        recall = recall_score(y_test, y_pred)
        f1 = f1_score(y_test, y_pred)

    print(f"\n{model_name} - РЕЗУЛЬТАТЫ:")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"F1-Score: {f1:.4f}")

    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
    print(f"Cross-validation Accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})")

    return {
        'model': model,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1': f1,
        'y_pred': y_pred,
        'y_pred_proba': y_pred_proba
    }

# kNN классификатор
print("kNN КЛАССИФИКАЦИЯ")

print("Подбор оптимального числа соседей (k):")
k_range = range(1, 15)
k_scores = []

for k in k_range:
    knn = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn, X_train_scaled, y_binary_train, cv=5, scoring='accuracy')
    k_scores.append(scores.mean())

optimal_k = k_range[np.argmax(k_scores)]
print(f"Оптимальное k: {optimal_k}")

plt.figure(figsize=(10, 6))
plt.plot(k_range, k_scores, 'bo-')
plt.xlabel('Число соседей (k)')
plt.ylabel('Accuracy')
plt.title('Подбор оптимального k для kNN')
plt.grid(True)
plt.show()

knn_binary = evaluate_model(
    KNeighborsClassifier(n_neighbors=optimal_k),
    X_train_scaled, X_test_scaled, y_binary_train, y_binary_test,
    "kNN (Бинарная классификация)"
)

knn_multi = evaluate_model(
    KNeighborsClassifier(n_neighbors=optimal_k),
    X_train_multi_scaled, X_test_multi_scaled, y_multi_train, y_multi_test,
    "kNN (Многоклассовая классификация)", multiclass=True
)

# Дерево решений
print("ДЕРЕВО РЕШЕНИЙ")


print("Подбор оптимальной глубины дерева:")
depth_range = range(1, 15)
depth_scores = []

for depth in depth_range:
    tree = DecisionTreeClassifier(max_depth=depth, random_state=42)
    scores = cross_val_score(tree, X_train, y_binary_train, cv=5, scoring='accuracy')
    depth_scores.append(scores.mean())

optimal_depth = depth_range[np.argmax(depth_scores)]
print(f"Оптимальная глубина: {optimal_depth}")

plt.figure(figsize=(10, 6))
plt.plot(depth_range, depth_scores, 'ro-')
plt.xlabel('Глубина дерева')
plt.ylabel('Accuracy')
plt.title('Подбор оптимальной глубины для дерева решений')
plt.grid(True)
plt.show()

tree_binary = evaluate_model(
    DecisionTreeClassifier(max_depth=optimal_depth, random_state=42),
    X_train, X_test, y_binary_train, y_binary_test,
    "Дерево решений (Бинарная классификация)"
)

tree_multi = evaluate_model(
    DecisionTreeClassifier(max_depth=optimal_depth, random_state=42),
    X_train_multi, X_test_multi, y_multi_train, y_multi_test,
    "Дерево решений (Многоклассовая классификация)", multiclass=True
)

# Матрицы ошибок
print("МАТРИЦЫ ОШИБОК")

fig, axes = plt.subplots(2, 2, figsize=(15, 12))

cm_knn_binary = confusion_matrix(y_binary_test, knn_binary['y_pred'])
cm_tree_binary = confusion_matrix(y_binary_test, tree_binary['y_pred'])

sns.heatmap(cm_knn_binary, annot=True, fmt='d', cmap='Blues', ax=axes[0,0])
axes[0,0].set_title('kNN - Матрица ошибок (Бинарная)')
axes[0,0].set_xlabel('Предсказанный класс')
axes[0,0].set_ylabel('Истинный класс')

sns.heatmap(cm_tree_binary, annot=True, fmt='d', cmap='Blues', ax=axes[0,1])
axes[0,1].set_title('Дерево решений - Матрица ошибок (Бинарная)')
axes[0,1].set_xlabel('Предсказанный класс')
axes[0,1].set_ylabel('Истинный класс')

cm_knn_multi = confusion_matrix(y_multi_test, knn_multi['y_pred'])
cm_tree_multi = confusion_matrix(y_multi_test, tree_multi['y_pred'])

sns.heatmap(cm_knn_multi, annot=True, fmt='d', cmap='Blues', ax=axes[1,0])
axes[1,0].set_title('kNN - Матрица ошибок (Многоклассовая)')
axes[1,0].set_xlabel('Предсказанный класс')
axes[1,0].set_ylabel('Истинный класс')

sns.heatmap(cm_tree_multi, annot=True, fmt='d', cmap='Blues', ax=axes[1,1])
axes[1,1].set_title('Дерево решений - Матрица ошибок (Многоклассовая)')
axes[1,1].set_xlabel('Предсказанный класс')
axes[1,1].set_ylabel('Истинный класс')

plt.tight_layout()
plt.show()

# ROC-кривые
print("ROC-КРИВЫЕ")

plt.figure(figsize=(10, 8))

fpr_knn, tpr_knn, _ = roc_curve(y_binary_test, knn_binary['y_pred_proba'][:, 1])
roc_auc_knn = auc(fpr_knn, tpr_knn)

fpr_tree, tpr_tree, _ = roc_curve(y_binary_test, tree_binary['y_pred_proba'][:, 1])
roc_auc_tree = auc(fpr_tree, tpr_tree)

plt.plot(fpr_knn, tpr_knn, color='blue', lw=2,
         label=f'kNN (AUC = {roc_auc_knn:.3f})')
plt.plot(fpr_tree, tpr_tree, color='red', lw=2,
         label=f'Дерево решений (AUC = {roc_auc_tree:.3f})')

plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--', label='Случайный классификатор')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-кривые для бинарной классификации')
plt.legend(loc="lower right")
plt.grid(True, alpha=0.3)
plt.show()

print(f"kNN AUC: {roc_auc_knn:.3f}")
print(f"Дерево решений AUC: {roc_auc_tree:.3f}")

# Сравнительный анализ моделей
print("СРАВНИТЕЛЬНЫЙ АНАЛИЗ МОДЕЛЕЙ")

comparison_data = {
    'Модель': ['kNN (Бинарная)', 'Дерево (Бинарная)', 'kNN (Многокласс)', 'Дерево (Многокласс)'],
    'Accuracy': [
        knn_binary['accuracy'],
        tree_binary['accuracy'],
        knn_multi['accuracy'],
        tree_multi['accuracy']
    ],
    'Precision': [
        knn_binary['precision'],
        tree_binary['precision'],
        knn_multi['precision'],
        tree_multi['precision']
    ],
    'Recall': [
        knn_binary['recall'],
        tree_binary['recall'],
        knn_multi['recall'],
        tree_multi['recall']
    ],
    'F1-Score': [
        knn_binary['f1'],
        tree_binary['f1'],
        knn_multi['f1'],
        tree_multi['f1']
    ]
}

comparison_df = pd.DataFrame(comparison_data)
display(comparison_df.round(4))

metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']

fig, axes = plt.subplots(2, 2, figsize=(15, 10))
axes = axes.ravel()

for i, metric in enumerate(metrics):
    if metric == 'F1-Score':
        key = 'f1'
    else:
        key = metric.lower()

    knn_values = [knn_binary[key], knn_multi[key]]
    tree_values = [tree_binary[key], tree_multi[key]]

    x = np.arange(2)
    width = 0.35

    axes[i].bar(x - width/2, knn_values, width, label='kNN', alpha=0.7)
    axes[i].bar(x + width/2, tree_values, width, label='Дерево решений', alpha=0.7)

    axes[i].set_xlabel('Тип классификации')
    axes[i].set_ylabel(metric)
    axes[i].set_title(f'Сравнение {metric}')
    axes[i].set_xticks(x)
    axes[i].set_xticklabels(['Бинарная', 'Многоклассовая'])
    axes[i].legend()
    axes[i].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

"""
ВЫВОД:

1. АНАЛИЗ ЦЕЛЕВОЙ ПЕРЕМЕННОЙ:
   Качество вина распределено неравномерно (несбалансированные классы)
   Преобладают вина среднего качества (5-6 баллов)
   Для улучшения результатов применено бинарное преобразование

2. kNN КЛАССИФИКАЦИЯ:
   Требует стандартизации данных
   Оптимальное число соседей: {}
   Хорошо работает с бинарной классификацией
   Чувствителен к выбросам и шуму в данных

3. ДЕРЕВО РЕШЕНИЙ:
   Не требует стандартизации данных
   Оптимальная глубина: {}
   Лучшая интерпретируемость результатов
   Склонно к переобучению при большой глубине

4. СРАВНИТЕЛЬНЫЙ АНАЛИЗ:
   Дерево решений показало лучшие результаты в бинарной классификации
   kNN эффективен при правильной предобработке данных
   Многоклассовая классификация сложнее из-за несбалансированности
   Оба метода имеют AUC > 0.8, что указывает на хорошее качество

5. ПРАКТИЧЕСКИЕ РЕКОМЕНДАЦИИ:
   Для данного датасета дерево решений более предпочтительно
   Для улучшения результатов можно применить ансамбли методов
   Рекомендуется сбор больше данных по редким классам качества
"""